Metadata-Version: 2.1
Name: nerdd-kafka
Version: 0.2.1
Summary: Run a NERDD module as a Kafka service
Home-page: https://github.com/molinfo-vienna/nerdd-kafka
Maintainer: Steffen Hirte
Maintainer-email: steffen.hirte@univie.ac.at
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: rdkit >=2022.3.3
Requires-Dist: kafka-python ==2.0.2
Requires-Dist: nerdd-module >=0.2.0
Requires-Dist: pandas >=1.2.1
Requires-Dist: pyyaml ~=6.0
Requires-Dist: filetype ~=1.2.0
Requires-Dist: rich-click >=1.7.1
Requires-Dist: stringcase ~=1.2.0
Requires-Dist: numpy
Requires-Dist: simplejson >=3
Provides-Extra: dev
Provides-Extra: docs
Requires-Dist: mkdocs ; extra == 'docs'
Requires-Dist: mkdocs-material ; extra == 'docs'
Provides-Extra: test
Requires-Dist: pytest ; extra == 'test'
Requires-Dist: pytest-cov ; extra == 'test'
Requires-Dist: pytest-asyncio ; extra == 'test'
Requires-Dist: pytest-bdd ; extra == 'test'
Requires-Dist: pytest-mock ; extra == 'test'
Requires-Dist: pytest-watch ; extra == 'test'
Requires-Dist: hypothesis ; extra == 'test'
Requires-Dist: hypothesis-rdkit ; extra == 'test'

# NERDD Kafka

Run a [NERDD module](https://github.com/molinfo-vienna/nerdd-module) as a Kafka 
service that consumes input molecules and produces prediction tuples.


## Installation

```bash
pip install -U nerdd-kafka
```
  
## Usage

When a class inherits from ```nerdd_module.AbstractModel``` (see 
[NERDD Module Github page](https://github.com/molinfo-vienna/nerdd-module)), it can be 
used to create a Kafka service. 

```bash 
# run a Kafka service for NerddModel on localhost:9092
run_nerdd_server package.path.to.NerddModel

# modify broker url, input topic and batch size
run_nerdd_server package.path.to.NerddModel \
  --broker-url my-cluster-kafka-bootstrap.kafka:9092 \
  --input-topic examples \
  --batch-size 10

# more information via --help
run_nerdd_server --help
```

If the model class is called ```ExamplePredictionModel```, the server will read input 
tuples from the input topic ```example-prediction-inputs``` in batches of size 100
and write results to the ```results``` topic. The batch size specifies the number
of input tuples that are given to the model at once.
