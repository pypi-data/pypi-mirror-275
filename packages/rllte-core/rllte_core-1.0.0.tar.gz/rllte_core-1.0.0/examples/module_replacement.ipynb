{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a62c2fb-0b1d-428c-b174-7d7edc919bde",
   "metadata": {},
   "source": [
    "**RLLTE** allows developers to replace settled modules of implemented algorithms to make performance comparison and algorithm improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d777f4-1cdf-4fee-a1b1-2a90f0fe33aa",
   "metadata": {},
   "source": [
    "# 1. Use built-in modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ddf33b-78ed-458b-affc-dae493eb4d2b",
   "metadata": {},
   "source": [
    "For instance, we want to use [PPO](https://arxiv.org/pdf/1707.06347) agent to solve [Atari](https://www.jair.org/index.php/jair/article/download/10819/25823) games, it suffices to write `train.py` like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28adfa3e-e6ca-495f-a1d3-2212169b4853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.4.0 (SDL 2.26.4, Python 3.8.16)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/29/2023 11:44:08 AM] - [\u001b[1m\u001b[34mINFO.\u001b[0m] - Invoking RLLTE Engine...\n",
      "[08/29/2023 11:44:08 AM] - [\u001b[1m\u001b[34mINFO.\u001b[0m] - ================================================================================\n",
      "[08/29/2023 11:44:08 AM] - [\u001b[1m\u001b[34mINFO.\u001b[0m] - Tag               : ppo_atari\n",
      "[08/29/2023 11:44:08 AM] - [\u001b[1m\u001b[34mINFO.\u001b[0m] - Device            : NVIDIA GeForce RTX 3090\n",
      "[08/29/2023 11:44:08 AM] - [\u001b[1m\u001b[33mDEBUG\u001b[0m] - Agent             : PPO\n",
      "[08/29/2023 11:44:08 AM] - [\u001b[1m\u001b[33mDEBUG\u001b[0m] - Encoder           : MnihCnnEncoder\n",
      "[08/29/2023 11:44:08 AM] - [\u001b[1m\u001b[33mDEBUG\u001b[0m] - Policy            : OnPolicySharedActorCritic\n",
      "[08/29/2023 11:44:08 AM] - [\u001b[1m\u001b[33mDEBUG\u001b[0m] - Storage           : VanillaRolloutStorage\n",
      "[08/29/2023 11:44:08 AM] - [\u001b[1m\u001b[33mDEBUG\u001b[0m] - Distribution      : Categorical\n",
      "[08/29/2023 11:44:08 AM] - [\u001b[1m\u001b[33mDEBUG\u001b[0m] - Augmentation      : False\n",
      "[08/29/2023 11:44:08 AM] - [\u001b[1m\u001b[33mDEBUG\u001b[0m] - Intrinsic Reward  : False\n",
      "[08/29/2023 11:44:08 AM] - [\u001b[1m\u001b[33mDEBUG\u001b[0m] - ================================================================================\n",
      "[08/29/2023 11:44:11 AM] - [\u001b[1m\u001b[32mEVAL.\u001b[0m] - S: 0           | E: 0           | L: 23          | R: 24.000      | T: 0:00:03    \n",
      "[08/29/2023 11:44:12 AM] - [\u001b[1m\u001b[31mTRAIN\u001b[0m] - S: 1024        | E: 8           | L: 44          | R: 99.000      | FPS: 219.815   | T: 0:00:04    \n",
      "[08/29/2023 11:44:13 AM] - [\u001b[1m\u001b[31mTRAIN\u001b[0m] - S: 2048        | E: 16          | L: 52          | R: 193.000     | FPS: 369.363   | T: 0:00:05    \n",
      "[08/29/2023 11:44:14 AM] - [\u001b[1m\u001b[31mTRAIN\u001b[0m] - S: 3072        | E: 24          | L: 39          | R: 88.000      | FPS: 474.345   | T: 0:00:06    \n",
      "[08/29/2023 11:44:14 AM] - [\u001b[1m\u001b[31mTRAIN\u001b[0m] - S: 4096        | E: 32          | L: 45          | R: 79.000      | FPS: 557.552   | T: 0:00:07    \n",
      "[08/29/2023 11:44:14 AM] - [\u001b[1m\u001b[34mINFO.\u001b[0m] - Training Accomplished!\n",
      "[08/29/2023 11:44:14 AM] - [\u001b[1m\u001b[34mINFO.\u001b[0m] - Model saved at: /export/yuanmingqi/code/rllte/examples/logs/ppo_atari/2023-08-29-11-44-07/model\n"
     ]
    }
   ],
   "source": [
    "from rllte.agent import PPO\n",
    "from rllte.env import make_atari_env\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # env setup\n",
    "    device = \"cuda:0\"\n",
    "    env = make_atari_env(device=device)\n",
    "    eval_env = make_atari_env(device=device)\n",
    "    # create agent\n",
    "    agent = PPO(env=env, \n",
    "                eval_env=eval_env, \n",
    "                device=device,\n",
    "                tag=\"ppo_atari\")\n",
    "    # start training\n",
    "    agent.train(num_train_steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e69a8f6-d0aa-47a7-b614-0facfa69979a",
   "metadata": {},
   "source": [
    "Suppose we want to use a `ResNet-based` encoder, it suffices to replace the encoder module using `.set` function. Run this cell and you'll see the old `MnihCnnEncoder` has been replaced by `EspeholtResidualEncoder`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f74896c-57b0-455c-9ec0-fff083c40b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/29/2023 11:44:42 AM] - [\u001b[1m\u001b[34mINFO.\u001b[0m] - Invoking RLLTE Engine...\n",
      "[08/29/2023 11:44:42 AM] - [\u001b[1m\u001b[34mINFO.\u001b[0m] - ================================================================================\n",
      "[08/29/2023 11:44:42 AM] - [\u001b[1m\u001b[34mINFO.\u001b[0m] - Tag               : ppo_atari\n",
      "[08/29/2023 11:44:42 AM] - [\u001b[1m\u001b[34mINFO.\u001b[0m] - Device            : NVIDIA GeForce RTX 3090\n",
      "[08/29/2023 11:44:42 AM] - [\u001b[1m\u001b[33mDEBUG\u001b[0m] - Agent             : PPO\n",
      "[08/29/2023 11:44:42 AM] - [\u001b[1m\u001b[33mDEBUG\u001b[0m] - Encoder           : EspeholtResidualEncoder\n",
      "[08/29/2023 11:44:42 AM] - [\u001b[1m\u001b[33mDEBUG\u001b[0m] - Policy            : OnPolicySharedActorCritic\n",
      "[08/29/2023 11:44:42 AM] - [\u001b[1m\u001b[33mDEBUG\u001b[0m] - Storage           : VanillaRolloutStorage\n",
      "[08/29/2023 11:44:42 AM] - [\u001b[1m\u001b[33mDEBUG\u001b[0m] - Distribution      : Categorical\n",
      "[08/29/2023 11:44:42 AM] - [\u001b[1m\u001b[33mDEBUG\u001b[0m] - Augmentation      : False\n",
      "[08/29/2023 11:44:42 AM] - [\u001b[1m\u001b[33mDEBUG\u001b[0m] - Intrinsic Reward  : False\n",
      "[08/29/2023 11:44:42 AM] - [\u001b[1m\u001b[33mDEBUG\u001b[0m] - ================================================================================\n",
      "[08/29/2023 11:44:44 AM] - [\u001b[1m\u001b[32mEVAL.\u001b[0m] - S: 0           | E: 0           | L: 66          | R: 130.000     | T: 0:00:02    \n",
      "[08/29/2023 11:44:46 AM] - [\u001b[1m\u001b[31mTRAIN\u001b[0m] - S: 1024        | E: 8           | L: 45          | R: 88.000      | FPS: 222.312   | T: 0:00:04    \n",
      "[08/29/2023 11:44:48 AM] - [\u001b[1m\u001b[31mTRAIN\u001b[0m] - S: 2048        | E: 16          | L: 51          | R: 107.000     | FPS: 347.909   | T: 0:00:05    \n",
      "[08/29/2023 11:44:49 AM] - [\u001b[1m\u001b[31mTRAIN\u001b[0m] - S: 3072        | E: 24          | L: 52          | R: 84.000      | FPS: 430.927   | T: 0:00:07    \n",
      "[08/29/2023 11:44:50 AM] - [\u001b[1m\u001b[31mTRAIN\u001b[0m] - S: 4096        | E: 32          | L: 56          | R: 117.000     | FPS: 496.024   | T: 0:00:08    \n",
      "[08/29/2023 11:44:50 AM] - [\u001b[1m\u001b[34mINFO.\u001b[0m] - Training Accomplished!\n",
      "[08/29/2023 11:44:50 AM] - [\u001b[1m\u001b[34mINFO.\u001b[0m] - Model saved at: /export/yuanmingqi/code/rllte/examples/logs/ppo_atari/2023-08-29-11-44-07/logs/ppo_atari/2023-08-29-11-44-42/model\n"
     ]
    }
   ],
   "source": [
    "from rllte.agent import PPO\n",
    "from rllte.env import make_atari_env\n",
    "from rllte.xploit.encoder import EspeholtResidualEncoder\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # env setup\n",
    "    device = \"cuda:0\"\n",
    "    env = make_atari_env(device=device)\n",
    "    eval_env = make_atari_env(device=device)\n",
    "    # create agent\n",
    "    feature_dim = 512\n",
    "    agent = PPO(env=env, \n",
    "                eval_env=eval_env, \n",
    "                device=device,\n",
    "                tag=\"ppo_atari\",\n",
    "                feature_dim=feature_dim)\n",
    "    # create a new encoder\n",
    "    encoder = EspeholtResidualEncoder(\n",
    "        observation_space=env.observation_space,\n",
    "        feature_dim=feature_dim)\n",
    "    # set the new encoder\n",
    "    agent.set(encoder=encoder)\n",
    "    # start training\n",
    "    agent.train(num_train_steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edc65be-93f9-4e30-b898-1399c9b4d836",
   "metadata": {},
   "source": [
    "For more replaceable modules, please refer to [https://docs.rllte.dev/api/](https://docs.rllte.dev/api/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc17a41-27b3-4dbd-9247-0b0fd87b5cea",
   "metadata": {},
   "source": [
    "# 2. Using custom modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d169736e-44db-4e89-9793-207c40eb0848",
   "metadata": {},
   "source": [
    "Developers can also perform replacement using custom modules, see [Make A Custom Module](https://docs.rllte.dev/tutorials/custom/module/) for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
