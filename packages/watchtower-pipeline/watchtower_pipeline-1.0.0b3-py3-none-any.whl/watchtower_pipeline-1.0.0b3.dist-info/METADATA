Metadata-Version: 2.1
Name: watchtower-pipeline
Version: 1.0.0b3
Summary: Utilities to generate static data for Watchtower.
License: GPL-3.0-or-later
Author: Francesco Siddi
Author-email: francesco@blender.org
Requires-Python: >=3.9,<4.0
Classifier: License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: requests (>=2.27.1,<3.0.0)
Requires-Dist: tqdm (>=4.62.3,<5.0.0)
Description-Content-Type: text/markdown

# Watchtower Pipeline

A Python package to generate data to be displayed in [Watchtower](https://watchtower.blender.org/).

Follow these instructions to deploy Watchtower in your production pipeline.

## Requirements
* Python 3.9+
* A source of production data (shots, assets, tasks, etc.)

## Setup

* Create a new folder, step into it and run:
* `python -m venv .venv`
* `source .venv/bin/activate`
* `pip install watchtower-pipeline`

### ... with example data
To create an example project that will give you an idea of how the pipeline works:

* Run `python -m watchtower_pipeline.example -b`
* Navigate to the `watchtower` folder and run `python -m http.server`

### ... with Kitsu-sourced data
If you have a working Kitsu (and Zou) installation and want to extract and visualize data from it:

* Create a `.env.local` file as follows:

  ```
  KITSU_DATA_SOURCE_URL=https://<your-kitsu-instance>/api
  KITSU_DATA_SOURCE_USER_EMAIL=user@example.org
  KITSU_DATA_SOURCE_USER_PASSWORD=password
  ```

* Run `python -m watchtower_pipeline.kitsu -b`
* Copy the content of the `watchtower` folder into your webserver
* Running the command without the `-b` flag will only fetch the data, and place it in a directory 
  called `public/data`, which can then be synced to where the `watchtower` folder has been placed.

### ... with custom-sourced data
If you use a different production/asset tracking service, some scripting will be required.  
Check `docs/integration.md` and `docs/develop-pipeline.md`.

